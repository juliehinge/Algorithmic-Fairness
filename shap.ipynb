{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 35\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Computing SHAP values\u001b[39;00m\n\u001b[1;32m     32\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m explainer\u001b[38;5;241m.\u001b[39mshap_values(X_test)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mshap_array\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_test_array\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     38\u001b[0m shap\u001b[38;5;241m.\u001b[39msummary_plot(shap_values, X_test, feature_names\u001b[38;5;241m=\u001b[39mX_columns)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_array' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed_data.csv')\n",
    "\n",
    "X = df.drop(['target'], axis=1)  # Drop the target column\n",
    "y = df['target']  # Assuming 'target' is your target column\n",
    "X_columns = X.columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Standardize numerical features if necessary\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=200, class_weight='balanced', solver='liblinear')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and confusion matrix\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Create a SHAP explainer object\n",
    "explainer = shap.Explainer(model, X_train, model_output=\"probability\")\n",
    "\n",
    "# Computing SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(X_test_array.shape)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test, feature_names=X_columns)\n",
    "\n",
    "print(X_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 57, Probabilities: Class 0 = 0.5000887785860346, Class 1 = 0.4999112214139653\n",
      "Index: 917, Probabilities: Class 0 = 0.4998945105362931, Class 1 = 0.5001054894637069\n",
      "Index: 232, Probabilities: Class 0 = 0.5002206510028951, Class 1 = 0.49977934899710486\n",
      "Index: 408, Probabilities: Class 0 = 0.5006259865795633, Class 1 = 0.4993740134204368\n",
      "Index: 111, Probabilities: Class 0 = 0.5007930045297032, Class 1 = 0.4992069954702968\n",
      "Index: 799, Probabilities: Class 0 = 0.5008608773154692, Class 1 = 0.4991391226845308\n",
      "Index: 41, Probabilities: Class 0 = 0.5011935579459983, Class 1 = 0.49880644205400165\n",
      "Index: 183, Probabilities: Class 0 = 0.5012382947074795, Class 1 = 0.4987617052925205\n",
      "Index: 696, Probabilities: Class 0 = 0.5013555868942845, Class 1 = 0.49864441310571556\n",
      "Index: 353, Probabilities: Class 0 = 0.5015603056042219, Class 1 = 0.49843969439577807\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming X_train_unscaled and y_train are already defined\n",
    "# X_train_unscaled should be a DataFrame including the 'gender' column\n",
    "\n",
    "# Sample data setup for demonstration (replace with your actual data)\n",
    "np.random.seed(42)\n",
    "X_train_unscaled = pd.DataFrame({\n",
    "    'feature1': np.random.randn(1000),\n",
    "    'feature2': np.random.randn(1000),\n",
    "    'gender': np.random.randint(0, 2, 1000)  # Randomly generating gender column\n",
    "})\n",
    "y_train = np.random.randint(0, 2, 1000)  # Random target variable\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_unscaled.drop(columns=['gender']), y_train)\n",
    "\n",
    "# Step 1: Filter the indices of rows where the gender column is 0\n",
    "gender_zero_indices = X_train_unscaled[X_train_unscaled['gender'] == 0].index\n",
    "\n",
    "# Step 2: Apply filtering to the X_train_unscaled dataset\n",
    "filtered_data = X_train_unscaled.loc[gender_zero_indices]\n",
    "\n",
    "# Extract features from the filtered data (excluding the 'gender' column)\n",
    "X_filtered = filtered_data.drop(columns=['gender'])\n",
    "\n",
    "# Step 4: Calculate the predicted probabilities for these data points\n",
    "probabilities = model.predict_proba(X_filtered)\n",
    "\n",
    "# Calculate the absolute difference between the probabilities of the two classes\n",
    "prob_diff = np.abs(probabilities[:, 0] - probabilities[:, 1])\n",
    "\n",
    "# Add the probabilities and their difference to the filtered_data DataFrame for easy sorting\n",
    "filtered_data['prob_class_0'] = probabilities[:, 0]\n",
    "filtered_data['prob_class_1'] = probabilities[:, 1]\n",
    "filtered_data['prob_diff'] = prob_diff\n",
    "\n",
    "# Step 5: Sort the data by the absolute difference between the class probabilities in ascending order\n",
    "sorted_filtered_data = filtered_data.sort_values(by='prob_diff')\n",
    "\n",
    "# Output the top 10 data points where the probabilities are most balanced\n",
    "top_10_balanced = sorted_filtered_data.head(10)\n",
    "\n",
    "# Display the probabilities for the top 10 balanced data points\n",
    "for index, row in top_10_balanced.iterrows():\n",
    "    print(f\"Index: {index}, Probabilities: Class 0 = {row['prob_class_0']}, Class 1 = {row['prob_class_1']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4482, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
